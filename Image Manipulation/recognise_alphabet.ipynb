{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train\n",
    "- Convert image to grayscale            ✅ (not necessary with current dataset)\n",
    "- Overlay images of the same alphabet   ✅\n",
    "- Make Weighted alphabet array          ✅\n",
    "- Normalize element magnitude           ✅\n",
    "\n",
    "Test\n",
    "- Compare with weighted alphabet array  ✅\n",
    "- compare each pixel with above pixel   ✅\n",
    "- measure the difference in brightness  ✅\n",
    "- least difference = most likely letter ✅\n",
    "- Display percentage                    ✅\n",
    "- Display top 3 matches                 ✅\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TRAINING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "\n",
    "import matplotlib.image as mimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image initialization\n",
    "\n",
    "# converts a B&W of shape (h, w, channels) to (h, w)\n",
    "def rgba2gray(img):\n",
    "    height, width, _ = img.shape\n",
    "    new_img = np.zeros(shape=(height, width))\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            new_img[i, j] = img.item((i, j, 0))\n",
    "    return new_img\n",
    "\n",
    "# luminosity method rgb to gray\n",
    "def rgb2gray(img):\n",
    "    height, width, _ = img.shape\n",
    "    gray_img_arr = np.zeros(shape=(height, width))\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            r_gray = img.item((i, j, 0)) * 0.299\n",
    "            g_gray = img.item((i, j, 1)) * 0.587\n",
    "            b_gray = img.item((i, j, 2)) * 0.114\n",
    "\n",
    "            gray_img_arr[i, j] = r_gray + g_gray + b_gray\n",
    "\n",
    "    return gray_img_arr\n",
    "\n",
    "\n",
    "# reads image from path and makes colorspace from 0-1\n",
    "def _get_image(path):\n",
    "    # img = cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
    "    img = mimg.imread(path)\n",
    "\n",
    "    if path.endswith('.jpg') or path.endswith('.tif') or path.endswith('.jpeg'):\n",
    "        return img / 255 # numpy is awesome\n",
    "    elif path.endswith('.png') and len(img.shape) > 2:\n",
    "        if img.shape[2] > 3:\n",
    "            return rgba2gray(img)\n",
    "\n",
    "    return img # 0-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVERLAY AND DEPENDENCIES\n",
    "\n",
    "# returns a weighted average of pixel values\n",
    "def _avg_pixel_weighted(channel_val1, weight1, channel_val2, weight2) -> int:\n",
    "    adjusted_weight_total = weight1 + weight2\n",
    "    return ((channel_val1 * weight1 + channel_val2 * weight2) / adjusted_weight_total)\n",
    "\n",
    "\n",
    "def overlay(img1, img2, img1_weight, img2_weight):\n",
    "\n",
    "    max_x_size = max(img1.shape[0], img2.shape[0])\n",
    "    max_y_size = max(img1.shape[1], img2.shape[1])\n",
    "\n",
    "    new_img_arr = np.zeros(shape=(max_x_size, max_y_size, 3))\n",
    "\n",
    "    for i in range(max_x_size):\n",
    "        for j in range(max_y_size):\n",
    "            # new_img_arr[i, j, k] = _avg_pixel_weighted(img1.item((i, j, k)), img1_weight, img2.item((i, j, k)), img2_weight)  # 4 sec\n",
    "            new_img_arr[i, j] = _avg_pixel_weighted(img1[i, j], img1_weight, img2[i, j], img2_weight)\n",
    "\n",
    "    return new_img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize image magnitude\n",
    "\n",
    "def normalize_img(trained_img):\n",
    "    multiplicant = 1/trained_img.max()\n",
    "\n",
    "    return trained_img * multiplicant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns image overlayed with all alphabets of a kind in dataset\n",
    "def trained_alphabet(path):\n",
    "\n",
    "    height, width = _get_image(os.path.join(path, os.listdir(path)[0])).shape\n",
    "    train_img = np.zeros(shape=(height, width))\n",
    "    no_of_elements = len(os.listdir(path))\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\".jpeg\"):\n",
    "            temp_train_img = _get_image(os.path.join(path, filename)) # 2D array of width, height (no channels, only magnitude of b-w pixel)\n",
    "\n",
    "            train_img = overlay(train_img, temp_train_img, no_of_elements, 1)\n",
    "\n",
    "    return normalize_img(train_img) # temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "\n",
    "'''\n",
    "plt.imsave('Trained_alpha/A_trained.png', trained_alphabet('Training_alpha/Alphabets/A'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/B_trained.png', trained_alphabet('Training_alpha/Alphabets/B'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/C_trained.png', trained_alphabet('Training_alpha/Alphabets/C'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/D_trained.png', trained_alphabet('Training_alpha/Alphabets/D'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/E_trained.png', trained_alphabet('Training_alpha/Alphabets/E'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/F_trained.png', trained_alphabet('Training_alpha/Alphabets/F'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/G_trained.png', trained_alphabet('Training_alpha/Alphabets/G'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/H_trained.png', trained_alphabet('Training_alpha/Alphabets/H'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/I_trained.png', trained_alphabet('Training_alpha/Alphabets/I'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/J_trained.png', trained_alphabet('Training_alpha/Alphabets/J'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/K_trained.png', trained_alphabet('Training_alpha/Alphabets/K'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/L_trained.png', trained_alphabet('Training_alpha/Alphabets/L'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/M_trained.png', trained_alphabet('Training_alpha/Alphabets/M'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/N_trained.png', trained_alphabet('Training_alpha/Alphabets/N'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/O_trained.png', trained_alphabet('Training_alpha/Alphabets/O'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/P_trained.png', trained_alphabet('Training_alpha/Alphabets/P'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/Q_trained.png', trained_alphabet('Training_alpha/Alphabets/Q'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/R_trained.png', trained_alphabet('Training_alpha/Alphabets/R'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/S_trained.png', trained_alphabet('Training_alpha/Alphabets/S'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/T_trained.png', trained_alphabet('Training_alpha/Alphabets/T'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/U_trained.png', trained_alphabet('Training_alpha/Alphabets/U'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/V_trained.png', trained_alphabet('Training_alpha/Alphabets/V'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/W_trained.png', trained_alphabet('Training_alpha/Alphabets/W'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/X_trained.png', trained_alphabet('Training_alpha/Alphabets/X'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/Y_trained.png', trained_alphabet('Training_alpha/Alphabets/Y'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/Z_trained.png', trained_alphabet('Training_alpha/Alphabets/Z'), cmap='gray')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TESTING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_alphabet(img):\n",
    "\n",
    "    accuracy_dict = {}\n",
    "    try:\n",
    "        height, width = img.shape\n",
    "    except ValueError:\n",
    "        height, width, _ = img.shape\n",
    "\n",
    "    for filename in sorted(os.listdir('Trained_alpha')):\n",
    "        if filename.endswith('.png'):\n",
    "\n",
    "            accuracy = 0 # difference of pixel value, lower is more accurate\n",
    "            accuracy_percent = 0\n",
    "            trained_img= _get_image(os.path.join('Trained_alpha', filename))\n",
    "\n",
    "            for i in range(height):\n",
    "                for j in range(width):\n",
    "                    pixel_val = trained_img[i, j]\n",
    "\n",
    "                    accuracy += abs(pixel_val - img[i, j]) # b/w 0-255\n",
    "\n",
    "            accuracy_percent = ((height * width * 255) - accuracy) * 100 / (height * width * 255)\n",
    "\n",
    "            accuracy_dict[filename] = accuracy_percent\n",
    "\n",
    "    # last three elements of list\n",
    "    maximum = sorted(accuracy_dict.values())[-3:]\n",
    "\n",
    "    # top match\n",
    "    # for k, v in accuracy_dict.items():\n",
    "    #     if v == maximum[-1]:\n",
    "    #         return f'{k[0]} with a percentage {v}'\n",
    "\n",
    "\n",
    "    # top 3 match\n",
    "    top_3 = []\n",
    "    for max_val in maximum[::-1]:\n",
    "        for key, value in accuracy_dict.items():\n",
    "            if value == max_val:\n",
    "                top_3.append((key[0], value))\n",
    "    return f'Top results:\\n {top_3[0][0]} with a percentage {top_3[0][1]}\\n {top_3[1][0]} with a percentage {top_3[1][1]}\\n {top_3[2][0]} with a percentage {top_3[2][1]}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Top results:\\n F with a percentage 99.87718515551931\\n P with a percentage 99.87496395466741\\n H with a percentage 99.87299506042808'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_alphabet(_get_image('Testing_alpha/15.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing accuracy with all images in an alphabet training set\n",
    "\n",
    "def accuracy_test(letter):\n",
    "    alphabet_dir = '../../../../07-Data/Training_alpha/Alphabets/' + letter\n",
    "    total = len(os.listdir(alphabet_dir))\n",
    "\n",
    "    # alphabet_dir = '../Image Manipulation/Testing_alpha'\n",
    "\n",
    "    correct = sum(\n",
    "        1\n",
    "        for img in os.listdir(alphabet_dir)\n",
    "        if img.endswith('.png')\n",
    "        and test_alphabet(_get_image(os.path.join(alphabet_dir, img)))[0]\n",
    "        == letter\n",
    "    )\n",
    "\n",
    "    return f'{letter} : {correct/total}'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "df955ce39d0f31d56d4bb2fe0a613e5326ba60723fd33d8303a3aede8f65715c"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
