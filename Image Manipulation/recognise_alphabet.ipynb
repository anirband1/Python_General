{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train\n",
    "- Convert image to grayscale            ✅ (not necessary with current dataset)\n",
    "- Overlay images of the same alphabet   ✅\n",
    "- Make Weighted alphabet array          ✅\n",
    "- Normalize element magnitude           ✅\n",
    "\n",
    "Test\n",
    "- Compare with weighted alphabet array\n",
    "- compare each pixel with above pixel\n",
    "- measure the difference in brightness\n",
    "- least difference = most likely letter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TRAINING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "\n",
    "import matplotlib.image as mimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image initialization\n",
    "\n",
    "def rgba2gray(img):\n",
    "    height, width, _ = img.shape\n",
    "    new_img = np.zeros(shape=(height, width))\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            new_img[i, j] = img.item((i, j, 0))\n",
    "    return new_img\n",
    "\n",
    "\n",
    "def _get_image(path):\n",
    "    # img = cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
    "    img = mimg.imread(path)\n",
    "\n",
    "    if path.endswith('.jpg') or path.endswith('.tif') or path.endswith('.jpeg'):\n",
    "        return img / 255 # numpy is awesome\n",
    "    elif path.endswith('.png') and len(img.shape) > 2:\n",
    "        if img.shape[2] > 3:\n",
    "            return rgba2gray(img)\n",
    "\n",
    "    return img # 0-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVERLAY AND DEPENDENCIES\n",
    "\n",
    "def _avg_pixel_weighted(channel_val1, weight1, channel_val2, weight2) -> int:\n",
    "    adjusted_weight_total = weight1 + weight2\n",
    "    return ((channel_val1 * weight1 + channel_val2 * weight2) / adjusted_weight_total)\n",
    "\n",
    "\n",
    "def overlay(img1, img2, img1_weight, img2_weight):\n",
    "\n",
    "    max_x_size = max(img1.shape[0], img2.shape[0])\n",
    "    max_y_size = max(img1.shape[1], img2.shape[1])\n",
    "\n",
    "    new_img_arr = np.zeros(shape=(max_x_size, max_y_size, 3))\n",
    "\n",
    "    for i in range(max_x_size):\n",
    "        for j in range(max_y_size):\n",
    "            # new_img_arr[i, j, k] = _avg_pixel_weighted(img1.item((i, j, k)), img1_weight, img2.item((i, j, k)), img2_weight)  # 4 sec\n",
    "            new_img_arr[i, j] = _avg_pixel_weighted(img1[i, j], img1_weight, img2[i, j], img2_weight)\n",
    "\n",
    "    return new_img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize image magnitude\n",
    "\n",
    "def normalize_img(trained_img):\n",
    "    multiplicant = 1/trained_img.max()\n",
    "\n",
    "    return trained_img * multiplicant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trained_alphabet(path):\n",
    "\n",
    "    # train_img = _get_image( os.path.join(path, sorted(os.listdir(path))[0]))\n",
    "\n",
    "    height, width = _get_image(os.path.join(path, os.listdir(path)[0])).shape\n",
    "    train_img = np.zeros(shape=(height, width))\n",
    "    no_of_elements = len(os.listdir(path))\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\".jpeg\"):\n",
    "            temp_train_img = _get_image(os.path.join(path, filename)) # 2D array of width, height (no channels, only magnitude of b-w pixel)\n",
    "\n",
    "            train_img = overlay(train_img, temp_train_img, no_of_elements, 1)\n",
    "\n",
    "    return normalize_img(train_img) # temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imsave('delete.jpg', train_model('Training_alpha/test', 'A'), cmap='gray')\n",
    "# train_model('Training_alpha/test', 'A')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "plt.imsave('Trained_alpha/A_trained.png', trained_alphabet('Training_alpha/Alphabets/A'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/B_trained.png', trained_alphabet('Training_alpha/Alphabets/B'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/C_trained.png', trained_alphabet('Training_alpha/Alphabets/C'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/D_trained.png', trained_alphabet('Training_alpha/Alphabets/D'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/E_trained.png', trained_alphabet('Training_alpha/Alphabets/E'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/F_trained.png', trained_alphabet('Training_alpha/Alphabets/F'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/G_trained.png', trained_alphabet('Training_alpha/Alphabets/G'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/H_trained.png', trained_alphabet('Training_alpha/Alphabets/H'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/I_trained.png', trained_alphabet('Training_alpha/Alphabets/I'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/J_trained.png', trained_alphabet('Training_alpha/Alphabets/J'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/K_trained.png', trained_alphabet('Training_alpha/Alphabets/K'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/L_trained.png', trained_alphabet('Training_alpha/Alphabets/L'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/M_trained.png', trained_alphabet('Training_alpha/Alphabets/M'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/N_trained.png', trained_alphabet('Training_alpha/Alphabets/N'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/O_trained.png', trained_alphabet('Training_alpha/Alphabets/O'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/P_trained.png', trained_alphabet('Training_alpha/Alphabets/P'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/Q_trained.png', trained_alphabet('Training_alpha/Alphabets/Q'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/R_trained.png', trained_alphabet('Training_alpha/Alphabets/R'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/S_trained.png', trained_alphabet('Training_alpha/Alphabets/S'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/T_trained.png', trained_alphabet('Training_alpha/Alphabets/T'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/U_trained.png', trained_alphabet('Training_alpha/Alphabets/U'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/V_trained.png', trained_alphabet('Training_alpha/Alphabets/V'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/W_trained.png', trained_alphabet('Training_alpha/Alphabets/W'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/X_trained.png', trained_alphabet('Training_alpha/Alphabets/X'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/Y_trained.png', trained_alphabet('Training_alpha/Alphabets/Y'), cmap='gray')\n",
    "plt.imsave('Trained_alpha/Z_trained.png', trained_alphabet('Training_alpha/Alphabets/Z'), cmap='gray')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TESTING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_alphabet(img):\n",
    "\n",
    "    accuracy_dict = {}\n",
    "    try:\n",
    "        height, width = img.shape\n",
    "    except ValueError:\n",
    "        height, width, _ = img.shape\n",
    "\n",
    "    for filename in sorted(os.listdir('Trained_alpha')):\n",
    "        if filename.endswith('.png'):\n",
    "\n",
    "            accuracy = 0\n",
    "            accuracy_percent = 0\n",
    "            trained_img= _get_image(os.path.join('Trained_alpha', filename))\n",
    "\n",
    "            for i in range(height):\n",
    "                for j in range(width):\n",
    "                    pixel_val = trained_img[i, j]\n",
    "\n",
    "                    accuracy += abs(pixel_val - img[i, j]) # clamp b/w 0-255\n",
    "\n",
    "                    # accuracy_total += accuracy\n",
    "                    \n",
    "                    # accuracy_percent += (255 - accuracy) / 255\n",
    "                    # total_value += pixel_val\n",
    "            accuracy_percent = ((height * width * 255) - accuracy) / (height * width * 255)\n",
    "\n",
    "            print(accuracy_percent)\n",
    "\n",
    "\n",
    "            # accuracy_percent = (total_value - accuracy) * 100/total_value # extreme => 0 or -255\n",
    "            # accuracy_percent /= 100\n",
    "            # accuracy_percent = sumof(255 - accuracy) / 255 # (255block - accuracyblock) / 255block\n",
    "\n",
    "            accuracy_dict[filename] = [accuracy, accuracy_percent]\n",
    "\n",
    "    minimum = accuracy_dict[list(accuracy_dict)[0]] [0] # first element of dict\n",
    "    # maximum = 0\n",
    "\n",
    "    for value in accuracy_dict.values():\n",
    "        minimum = min(minimum, value[0])\n",
    "        # maximum = max(maximum, value)\n",
    "\n",
    "    for key, value in accuracy_dict.items():\n",
    "        if value[0] == minimum:\n",
    "        # if value == maximum:\n",
    "            # return f'{key[0]} with a percentage of {maximum}%'\n",
    "            return f'{key[0]} with a percentage of {value[1]}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7641812158740322\n",
      "0.8048062165526062\n",
      "0.8418964444199446\n",
      "0.7467945748207967\n",
      "0.8847234972326987\n",
      "0.8356387843828088\n",
      "0.7591605368943419\n",
      "0.7494561848989179\n",
      "0.7680453399457292\n",
      "0.7399701233111955\n",
      "0.7967026629848988\n",
      "1.0\n",
      "0.6715494742938972\n",
      "0.7297832373842539\n",
      "0.7323874050844097\n",
      "0.7798674908531211\n",
      "0.7486825955620589\n",
      "0.7743183185598355\n",
      "0.8144531222583282\n",
      "0.7673598315304844\n",
      "0.764146749374504\n",
      "0.7735906828802399\n",
      "0.7021254550581943\n",
      "0.800597423479303\n",
      "0.7786764672605386\n",
      "0.8274050219779383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'L with a percentage of 1.0'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_alphabet(_get_image('Testing_alpha/L.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "df955ce39d0f31d56d4bb2fe0a613e5326ba60723fd33d8303a3aede8f65715c"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
